{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa8d80-9690-4fd4-a40a-152e083e066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralprophet import NeuralProphet\n",
    "import yfinance as yf\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import requests\n",
    "import gensim\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from collections import namedtuple\n",
    "from bs4 import BeautifulSoup as bs\n",
    "# from gensim.models import CoherenceModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79af7aa-0ade-40f2-88cb-14a097e50e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('finalp6apr/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921930f6-7417-44b6-90ae-23a16d94ca9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac58c456-de2c-4f72-8633-d3010e95a0a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_words_with_order(words):\n",
    "    word_count_dict = {}\n",
    "    for word in words:\n",
    "        word_count_dict[word] = word_count_dict.get(word, 0) + 1\n",
    "    return pd.Series(word_count_dict)\n",
    "\n",
    "word_counts_per_paper = df.dropna().groupby('Paper_ID')['Token_Text'].apply(lambda x: x.str.split().apply(count_words_with_order)).reset_index()\n",
    "\n",
    "\n",
    "word_counts_per_paper = word_counts_per_paper.melt(id_vars='Paper_ID', var_name='Word', value_name='Count').dropna()\n",
    "unwanted_words = [r'^\\d+( \\d+)*$',\n",
    "                  r'\\b\\w*[0-9]+\\b',\n",
    "                  r'© UCLES',r'cid',\n",
    "                  r'\\.{10,}',r'^\\.{3,}',\n",
    "                  r'^© UCLES \\d+\\s*$',\n",
    "                  r'^\\[Total:\\s*\\d+\\]$',\n",
    "                  r'^\\d+\\s*(BLANK PAGE|TURN OVER|Additional Pages)',\n",
    "                  r'^\\d+\\s*[A-Z]+\\s*\\d+/\\d+/\\d+','scale','km','mm',\n",
    "                  'type','cm','one','impact','level_1','Study','map',\n",
    "                  'area','shown','feature','extract','Describe','two',\n",
    "                  'east','north','south','west','Table','grid','Ballvaghan']\n",
    "word_counts_per_paper['Word'] = word_counts_per_paper['Word'].apply(lambda x: '' if x in unwanted_words else x)\n",
    "\n",
    "\n",
    "word_counts_per_paper = word_counts_per_paper[word_counts_per_paper['Word'] != '']\n",
    "\n",
    "\n",
    "print(word_counts_per_paper.head())\n",
    "\n",
    "\n",
    "\n",
    "for paper_id, paper_data in word_counts_per_paper.groupby('Paper_ID'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(paper_data['Word'], paper_data['Count'], marker='o', linestyle='-', label=paper_id)\n",
    "    plt.title('Word Counts for Paper: ' + paper_id)\n",
    "    plt.xlabel('Word')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5569cb-9802-4c9d-bb1d-e3bcb0ed2b5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from geotext import GeoText\n",
    "def count_words_with_order(words):\n",
    "    word_count_dict = {}\n",
    "    for word in words:\n",
    "        word_count_dict[word] = word_count_dict.get(word, 0) + 1\n",
    "    return pd.Series(word_count_dict)\n",
    "\n",
    "word_counts_per_paper = df.dropna().groupby('Paper_ID')['Token_Text'].apply(lambda x: x.str.split().apply(count_words_with_order)).reset_index()\n",
    "word_counts_per_paper = word_counts_per_paper.melt(id_vars='Paper_ID', var_name='Word', value_name='Count').dropna()\n",
    "\n",
    "unwanted_words = ['scale','km','mm','type','cm','one','impact','level_1','Study','map','area','shown','feature',\n",
    "                  'extract','Describe','two','east','north','south','west','Table', 'grid','Ballyvaghan']\n",
    "\n",
    "word_counts_per_paper['Word'] = word_counts_per_paper['Word'].apply(lambda x: '' if any(char.isdigit() for char in x) or x in unwanted_words else x)\n",
    "word_counts_per_paper = word_counts_per_paper[word_counts_per_paper['Word'] != '']\n",
    "\n",
    "for paper_id, paper_data in word_counts_per_paper.groupby('Paper_ID'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(paper_data['Word'], paper_data['Count'], marker='o', linestyle='-', label=paper_id)\n",
    "    plt.title('Word Counts for Paper: ' + paper_id)\n",
    "    plt.xlabel('Word')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132a8906-7f5d-4e0a-ad18-d08ccad8a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Download the wordnet corpus if not already downloaded\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function to check if a word is a city or country name\n",
    "def is_city_or_country(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    for synset in synsets:\n",
    "        if synset.lexname() == 'toponym':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Extract city and country names from text\n",
    "def extract_places(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    places = [word for word in words if is_city_or_country(word)]\n",
    "    return places\n",
    "\n",
    "# Apply the function to extract places for each row in the DataFrame\n",
    "places = df['Token_Text'].dropna().apply(extract_places)\n",
    "\n",
    "# Flatten the list of lists into a single list of places\n",
    "all_places = [place for sublist in places for place in sublist]\n",
    "\n",
    "# Convert the list to a set to remove duplicates\n",
    "unique_places = set(all_places)\n",
    "\n",
    "# Convert the set back to a list\n",
    "unwanted_words = list(unique_places)\n",
    "\n",
    "# Filter out unwanted words\n",
    "word_counts_per_paper['Word'] = word_counts_per_paper['Word'].apply(lambda x: '' if any(char.isdigit() for char in x) or x in unwanted_words else x)\n",
    "\n",
    "# Filter out rows with empty words\n",
    "word_counts_per_paper = word_counts_per_paper[word_counts_per_paper['Word'] != '']\n",
    "\n",
    "print(word_counts_per_paper.head())\n",
    "\n",
    "for paper_id, paper_data in word_counts_per_paper.groupby('Paper_ID'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(paper_data['Word'], paper_data['Count'], marker='o', linestyle='-', label=paper_id)\n",
    "    plt.title('Word Counts for Paper: ' + paper_id)\n",
    "    plt.xlabel('Word')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911782bd-2206-49de-a1d6-95e9df898df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# Function to count words within each group\n",
    "def count_words(group):\n",
    "    word_counts = group.str.split().explode().value_counts()\n",
    "    return word_counts\n",
    "\n",
    "# Apply the count_words function within each group defined by Paper_ID\n",
    "word_counts_per_paper = df.groupby('Paper_ID')['Token_Text'].apply(count_words).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "word_counts_per_paper.columns = ['Paper_ID', 'Word', 'Count']\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(word_counts_per_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7a117-a2d3-4435-bb30-7f8f41b80f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for paper_id, paper_data in word_counts_per_paper.groupby('Paper_ID'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(paper_data['Word'], paper_data['Count'], marker='o', linestyle='-', label=paper_id)\n",
    "    plt.title('Word Counts for Paper: ' + paper_id)\n",
    "    plt.xlabel('Word')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82208a8f-0136-46cc-a0e5-444e853b002f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
